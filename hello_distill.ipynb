{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a56a0e7-47ff-4764-96a4-e1a3d4f22387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from datasets import load_dataset\n",
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "from mlx_lm import load, generate\n",
    "import mlx.optimizers as optim\n",
    "from mlx.utils import tree_map, tree_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8e2546d7-b894-4ca1-a6b8-e2b8d6c12651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f6e4c8b3ce42e5aa5d25cb9e97b2b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 128k vocab size\n",
    "teacher, tokenizer = load(\"mlx-community/Llama-3.2-1B-Instruct-4bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "decc874e-4bb3-4fe5-a929-caa36a19e60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94560cc83aec4e2a8ad2914b643bdf96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ctx_len = 256\n",
    "\n",
    "def prepare(x):\n",
    "    x = tokenizer.encode(x[\"text\"][0])\n",
    "    cutoff = (len(x) // ctx_len) * ctx_len\n",
    "    x = x[:cutoff]\n",
    "    return { \"ids\": [x[i:i+ctx_len] for i in range(0, len(x), ctx_len)] }\n",
    "\n",
    "ds = load_dataset(\"flpelerin/tinystories-100k\", split=\"train\")\n",
    "ds = ds.map(prepare, batched=True, batch_size=1, remove_columns=ds.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "05cd36fc-9edb-4ba1-b702-4581d9b2ac88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelArgs(model_type='llama', hidden_size=2048, num_hidden_layers=16, intermediate_size=8192, num_attention_heads=32, rms_norm_eps=1e-05, vocab_size=128256, head_dim=64, max_position_embeddings=131072, num_key_value_heads=8, attention_bias=False, mlp_bias=False, rope_theta=500000.0, rope_traditional=False, rope_scaling={'factor': 32.0, 'high_freq_factor': 4.0, 'low_freq_factor': 1.0, 'original_max_position_embeddings': 8192, 'rope_type': 'llama3'}, tie_word_embeddings=True)\n"
     ]
    }
   ],
   "source": [
    "print(teacher.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8e9f4ed2-5ed9-4d6b-b1e4-efda7b5588c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_params 80956224\n"
     ]
    }
   ],
   "source": [
    "args = deepcopy(teacher.args)\n",
    "args.num_key_value_heads = 3\n",
    "args.num_attention_heads = 9\n",
    "args.head_dim = 64\n",
    "args.hidden_size = 576\n",
    "args.intermediate_size = 1536\n",
    "args.num_hidden_layers = 2\n",
    "\n",
    "model = type(teacher)(args)\n",
    "mx.eval(model.parameters())\n",
    "print(\"n_params\", sum(v.size for _, v in tree_flatten(model.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0cc85c19-9abf-4625-97a1-e3dd54999666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, x, y):\n",
    "    teacher_softmax = nn.softmax(y)\n",
    "    teacher_log_softmax = nn.log_softmax(y)\n",
    "    student_log_softmax = nn.log_softmax(model(x))\n",
    "    return mx.mean(mx.sum(teacher_softmax * (teacher_log_softmax - student_log_softmax), axis=-1))\n",
    "\n",
    "optimizer = optim.AdamW(learning_rate=0.0001)\n",
    "step = nn.value_and_grad(model, loss)\n",
    "\n",
    "state = [model.state, optimizer.state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5e31aeca-c131-4820-a90a-e8e033f81047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0, loss: 10.559500694274902, lr: 0.00010\n",
      "iter: 1, loss: 9.183050155639648, lr: 0.00010\n",
      "iter: 2, loss: 8.637887001037598, lr: 0.00010\n",
      "iter: 3, loss: 8.360408782958984, lr: 0.00010\n",
      "iter: 4, loss: 7.685101509094238, lr: 0.00010\n",
      "iter: 5, loss: 7.479364395141602, lr: 0.00009\n",
      "iter: 6, loss: 7.132399559020996, lr: 0.00009\n",
      "iter: 7, loss: 6.698503494262695, lr: 0.00009\n",
      "iter: 8, loss: 6.323685646057129, lr: 0.00009\n",
      "iter: 9, loss: 6.087820053100586, lr: 0.00009\n",
      "iter: 10, loss: 5.876641273498535, lr: 0.00009\n",
      "iter: 11, loss: 5.553765773773193, lr: 0.00009\n",
      "iter: 12, loss: 5.357820510864258, lr: 0.00009\n",
      "iter: 13, loss: 5.042308330535889, lr: 0.00009\n",
      "iter: 14, loss: 4.88326358795166, lr: 0.00009\n",
      "iter: 15, loss: 4.839049816131592, lr: 0.00008\n",
      "iter: 16, loss: 4.7905144691467285, lr: 0.00008\n",
      "iter: 17, loss: 4.737854957580566, lr: 0.00008\n",
      "iter: 18, loss: 4.692557334899902, lr: 0.00008\n",
      "iter: 19, loss: 4.5652875900268555, lr: 0.00008\n",
      "iter: 20, loss: 4.624118804931641, lr: 0.00008\n",
      "iter: 21, loss: 4.3998308181762695, lr: 0.00008\n",
      "iter: 22, loss: 4.425207614898682, lr: 0.00008\n",
      "iter: 23, loss: 4.400042533874512, lr: 0.00008\n",
      "iter: 24, loss: 4.4307026863098145, lr: 0.00008\n",
      "iter: 25, loss: 4.490259647369385, lr: 0.00007\n",
      "iter: 26, loss: 4.262730598449707, lr: 0.00007\n",
      "iter: 27, loss: 4.426399230957031, lr: 0.00007\n",
      "iter: 28, loss: 4.216771125793457, lr: 0.00007\n",
      "iter: 29, loss: 4.294156074523926, lr: 0.00007\n",
      "iter: 30, loss: 4.806400299072266, lr: 0.00007\n",
      "iter: 31, loss: 4.718172073364258, lr: 0.00007\n",
      "iter: 32, loss: 4.8398756980896, lr: 0.00007\n",
      "iter: 33, loss: 5.02800178527832, lr: 0.00007\n",
      "iter: 34, loss: 4.57427978515625, lr: 0.00007\n",
      "iter: 35, loss: 4.841819763183594, lr: 0.00006\n",
      "iter: 36, loss: 4.163552761077881, lr: 0.00006\n",
      "iter: 37, loss: 4.253683090209961, lr: 0.00006\n",
      "iter: 38, loss: 4.16880464553833, lr: 0.00006\n",
      "iter: 39, loss: 4.168182373046875, lr: 0.00006\n",
      "iter: 40, loss: 4.272280216217041, lr: 0.00006\n",
      "iter: 41, loss: 4.285755157470703, lr: 0.00006\n",
      "iter: 42, loss: 4.1485161781311035, lr: 0.00006\n",
      "iter: 43, loss: 4.314589977264404, lr: 0.00006\n",
      "iter: 44, loss: 4.081640720367432, lr: 0.00006\n",
      "iter: 45, loss: 3.9999208450317383, lr: 0.00005\n",
      "iter: 46, loss: 4.013877868652344, lr: 0.00005\n",
      "iter: 47, loss: 4.097847938537598, lr: 0.00005\n",
      "iter: 48, loss: 4.000406742095947, lr: 0.00005\n",
      "iter: 49, loss: 3.9440300464630127, lr: 0.00005\n",
      "iter: 50, loss: 4.000309944152832, lr: 0.00005\n",
      "iter: 51, loss: 4.4388427734375, lr: 0.00005\n",
      "iter: 52, loss: 3.8638787269592285, lr: 0.00005\n",
      "iter: 53, loss: 3.802292823791504, lr: 0.00005\n",
      "iter: 54, loss: 3.9541783332824707, lr: 0.00005\n",
      "iter: 55, loss: 3.696092128753662, lr: 0.00004\n",
      "iter: 56, loss: 3.790497303009033, lr: 0.00004\n",
      "iter: 57, loss: 3.6981539726257324, lr: 0.00004\n",
      "iter: 58, loss: 3.711808681488037, lr: 0.00004\n",
      "iter: 59, loss: 3.6085360050201416, lr: 0.00004\n",
      "iter: 60, loss: 3.8328473567962646, lr: 0.00004\n",
      "iter: 61, loss: 4.105279922485352, lr: 0.00004\n",
      "iter: 62, loss: 4.28978157043457, lr: 0.00004\n",
      "iter: 63, loss: 4.5199480056762695, lr: 0.00004\n",
      "iter: 64, loss: 4.255505084991455, lr: 0.00004\n",
      "iter: 65, loss: 4.256927967071533, lr: 0.00003\n",
      "iter: 66, loss: 4.316067695617676, lr: 0.00003\n",
      "iter: 67, loss: 4.31641960144043, lr: 0.00003\n",
      "iter: 68, loss: 4.237344741821289, lr: 0.00003\n",
      "iter: 69, loss: 4.0776214599609375, lr: 0.00003\n",
      "iter: 70, loss: 4.354597091674805, lr: 0.00003\n",
      "iter: 71, loss: 4.245055675506592, lr: 0.00003\n",
      "iter: 72, loss: 4.027496814727783, lr: 0.00003\n",
      "iter: 73, loss: 3.866818428039551, lr: 0.00003\n",
      "iter: 74, loss: 3.9874746799468994, lr: 0.00003\n",
      "iter: 75, loss: 4.168922424316406, lr: 0.00002\n",
      "iter: 76, loss: 3.9514877796173096, lr: 0.00002\n",
      "iter: 77, loss: 3.7483434677124023, lr: 0.00002\n",
      "iter: 78, loss: 3.7840042114257812, lr: 0.00002\n",
      "iter: 79, loss: 3.665435791015625, lr: 0.00002\n",
      "iter: 80, loss: 3.6072936058044434, lr: 0.00002\n",
      "iter: 81, loss: 3.6834497451782227, lr: 0.00002\n",
      "iter: 82, loss: 3.669299602508545, lr: 0.00002\n",
      "iter: 83, loss: 3.577892780303955, lr: 0.00002\n",
      "iter: 84, loss: 3.522174835205078, lr: 0.00002\n",
      "iter: 85, loss: 3.5432591438293457, lr: 0.00001\n",
      "iter: 86, loss: 3.6172189712524414, lr: 0.00001\n",
      "iter: 87, loss: 3.784973621368408, lr: 0.00001\n",
      "iter: 88, loss: 3.7196662425994873, lr: 0.00001\n",
      "iter: 89, loss: 3.5291457176208496, lr: 0.00001\n",
      "iter: 90, loss: 3.888148069381714, lr: 0.00001\n",
      "iter: 91, loss: 3.7635674476623535, lr: 0.00001\n",
      "iter: 92, loss: 3.626405715942383, lr: 0.00001\n",
      "iter: 93, loss: 3.645972490310669, lr: 0.00001\n",
      "iter: 94, loss: 3.626429557800293, lr: 0.00001\n",
      "iter: 95, loss: 3.5509238243103027, lr: 0.00000\n",
      "iter: 96, loss: 3.497966766357422, lr: 0.00000\n",
      "iter: 97, loss: 3.7822775840759277, lr: 0.00000\n",
      "iter: 98, loss: 3.9833855628967285, lr: 0.00000\n",
      "iter: 99, loss: 4.003050804138184, lr: 0.00000\n"
     ]
    }
   ],
   "source": [
    "B=8\n",
    "for i in range(0, 100):\n",
    "    x = mx.array(ds[i*B:i*B+B][\"ids\"])\n",
    "    y = teacher(x)\n",
    "\n",
    "    loss, grads = step(model, x, y)\n",
    "    optimizer.update(model, grads)\n",
    "    mx.eval(state)\n",
    "\n",
    "    print(f\"iter: {i}, loss: {loss}, lr: {optimizer.learning_rate:.5f}\")\n",
    "    optimizer.learning_rate -= 0.000001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "016f8b84-2b45-4e51-a3f5-fbf6abff6516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|>Once upon a time, in a big, green park, there was a small, messy dog. The proud blocks! her'shelter. They branch. She do walked were teacher nods, they said. atικοί. She saw Ther. We idea at it is that trapped eager, \" \n",
      " four brings that other bed to the king on the tree are.\n",
      "\n",
      "S thought that a dog,led away that a prizes drink and, \"I brown and looked.\n",
      "\n",
      "\",、お had Career and happy\n"
     ]
    }
   ],
   "source": [
    "def generate(model, str, n):\n",
    "    x = mx.array(tokenizer.encode(str))[None, :]\n",
    "    for _ in range(n):\n",
    "        y = model(x)\n",
    "        x = mx.concatenate([x, mx.random.categorical(y[:, -1])[None, :]], axis=1)\n",
    "    return tokenizer.decode(x[0].tolist())\n",
    "\n",
    "print(generate(model, tokenizer.decode(ds[0][\"ids\"][:20]), 80))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
